{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code for how the synthetic data was generated and metric results were computed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from faker import Faker\n",
    "import random\n",
    "from synthesis.synthesizers.privbayes import PrivBayes\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from Metrics import All_synthcity\n",
    "from Metrics import AttributeInference1 as AIR\n",
    "from Metrics import CGeneralizedCAP as GCAP\n",
    "from Metrics import CZeroCAP as CZCAP\n",
    "from Metrics import NNAA\n",
    "from Metrics import MemInf as MIR\n",
    "from Metrics import Hitting_rate\n",
    "from Metrics import MDCR\n",
    "from Metrics import DCR\n",
    "from Metrics import NNDR\n",
    "from Metrics import Hidden_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Real dataset generation definition\n",
    "\n",
    "def generate_real_data(num_samples):\n",
    "    name_gen = Faker()\n",
    "    heights = np.around(list(np.random.normal(loc=170, scale=10, size=num_samples)), 2)\n",
    "    classic_icecreams = [\n",
    "        \"Vanilla\", \"Chocolate\", \"Strawberry\", \"Mint Chocolate Chip\",\n",
    "        \"Cookies and Cream\", \"Rocky Road\", \"Butter Pecan\", \"Neapolitan\",\n",
    "        \"Pistachio\", \"French Vanilla\"\n",
    "    ]\n",
    "    fav_icecream = list(random.choices(classic_icecreams, k=num_samples))\n",
    "\n",
    "    # Generate random first and last names\n",
    "    name_df = pd.DataFrame({\n",
    "        'First Name': [name_gen.first_name() for _ in range(num_samples)],\n",
    "        'Last Name': [name_gen.last_name() for _ in range(num_samples)]\n",
    "    })\n",
    "    height_df = pd.DataFrame({'Height': heights})\n",
    "    icecream_df = pd.DataFrame({'Flavour': fav_icecream})\n",
    "    basic_df = pd.concat([name_df, height_df, icecream_df], axis=1)\n",
    "    \n",
    "    # Set random seed for reproducibility\n",
    "    random.seed(42)\n",
    "    np.random.seed(42)\n",
    "\n",
    "    # Define country list and correlation rules\n",
    "    countries = [\"USA\", \"Canada\", \"Germany\", \"France\", \"Italy\", \"China\", \"Brazil\", \"Australia\", \"Japan\", \"UK\", \"Sweden\", \"Norway\", \"Denmark\", \"Finland\"]\n",
    "\n",
    "    # Ice cream preferences (default: random choice)\n",
    "    ice_creams = [\"Vanilla\", \"Chocolate\", \"Strawberry\", \"Mint\", \"Pistachio\", \"Stracciatella\"]\n",
    "\n",
    "    # Generate data\n",
    "    data = []\n",
    "    for i in range(num_samples):\n",
    "        person = {}\n",
    "\n",
    "        # Assign country\n",
    "        person[\"Country of Origin\"] = random.choice(countries)\n",
    "\n",
    "        # Assign favorite ice cream with correlation (Italy → Stracciatella preference)\n",
    "        if person[\"Country of Origin\"] == \"Italy\":\n",
    "            person[\"Favorite Icecream\"] = np.random.choice(ice_creams, p=[0.1, 0.1, 0.1, 0.1, 0.2, 0.4])\n",
    "        else:\n",
    "            person[\"Favorite Icecream\"] = random.choice(ice_creams)\n",
    "\n",
    "        # Assign liking for liquorice (Nordic countries → Higher probability)\n",
    "        if person[\"Country of Origin\"] in [\"Sweden\", \"Norway\", \"Denmark\", \"Finland\"]:\n",
    "            person[\"Like Liquorice\"] = np.random.choice([1, 0], p=[0.9, 0.1])  # 70% chance for Nordic countries\n",
    "        else:\n",
    "            person[\"Like Liquorice\"] = np.random.choice([1, 0], p=[0.2, 0.8])  # 20% for others\n",
    "\n",
    "        # Assign number of times visited Italy (Random integer, but higher if from Europe)\n",
    "        if person[\"Country of Origin\"] in [\"Germany\", \"France\", \"UK\", \"Sweden\", \"Norway\", \"Denmark\", \"Finland\", \"Italy\"]:\n",
    "            person[\"Times Visited Italy\"] = np.random.poisson(2)  # Higher average visits\n",
    "        else:\n",
    "            person[\"Times Visited Italy\"] = np.random.poisson(0.5)  # Lower average visits\n",
    "\n",
    "        # First time in London (UK residents more likely to say yes)\n",
    "        person[\"First Time London\"] = 1 if person[\"Country of Origin\"] == \"UK\" else np.random.choice([1, 0], p=[0.2, 0.8])\n",
    "\n",
    "        # Number of steps per day (Normal distribution with realistic values)\n",
    "        person[\"Steps per Day\"] = max(1000, int(np.random.normal(8000, 3000)))  # Avoids negative steps\n",
    "\n",
    "        data.append(person)\n",
    "\n",
    "    # Create DataFrame\n",
    "    df = pd.DataFrame(data)\n",
    "    \n",
    "    full_df = pd.concat([basic_df, df], axis=1)\n",
    "    \n",
    "    return full_df\n",
    "\n",
    "num_samples = 1500\n",
    "\n",
    "real_data = generate_real_data(num_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Synthesize dataset with PrivBayes\n",
    "def synthesize_no_bin(real_data, eps):    \n",
    "    # instantiate and fit synthesizer\n",
    "    pb = PrivBayes(epsilon=eps, verbose=False)\n",
    "    pb.fit(real_data)\n",
    "\n",
    "    # Synthesize data\n",
    "    gen_data  = pb.sample()\n",
    "\n",
    "    # Save to csv file\n",
    "    result = pd.DataFrame(gen_data.values, columns=gen_data.columns, index=range(real_data.shape[0]))\n",
    "    \n",
    "    return result\n",
    "\n",
    "eps_list = [0.02, 0.05, 0.1, 0.2, 0.5, 1, 2.5, 5]\n",
    "for eps in eps_list:\n",
    "    synthesize_no_bin(real_data, eps).to_csv(f\"demo_syn/syn_no_1_{eps}.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get metric results\n",
    "def get_metric_results(real_data, syn_data):\n",
    "    real_data['Height'].astype('Float32')\n",
    "    syn_data['Height'].astype('Float32')\n",
    "\n",
    "    all_data = pd.concat([real_data, syn_data])\n",
    "    fn_encoder = LabelEncoder()\n",
    "    ln_encoder = LabelEncoder()\n",
    "    fl_encoder = LabelEncoder()\n",
    "    na_encoder = LabelEncoder()\n",
    "    r_fn = fn_encoder.fit_transform(all_data['First Name'])\n",
    "    r_ln = ln_encoder.fit_transform(all_data['Last Name'])\n",
    "    r_na = na_encoder.fit_transform(all_data['Nationality'])\n",
    "    r_fl = fl_encoder.fit_transform(all_data['Favorite Icecream'])\n",
    "    all_labels = pd.DataFrame({'First Name':r_fn, 'Last Name': r_ln, 'Height': all_data['Height'],'Nationality': r_na, 'Favorite Icecream':r_fl, 'Like Liquorice': all_data['Like Liquorice'], 'Times Been to Italy': all_data['Times Been to Italy'], 'First Time London': all_data['First Time London'], 'Steps per Day': all_data['Steps per Day']})\n",
    "    real_labels = all_labels[:len(real_data)]\n",
    "    syn_labels = all_labels[-len(real_data):]\n",
    "    \n",
    "    metrics = {\n",
    "                    'sanity': ['common_rows_proportion', 'nearest_syn_neighbor_distance', 'close_values_probability', 'distant_values_probability'],\n",
    "                    'stats': ['alpha_precision'],\n",
    "                    'detection': ['detection_mlp'],\n",
    "                    'privacy': ['identifiability_score'],\n",
    "                }\n",
    "    \n",
    "    synthcity_results = All_synthcity.calculate_metric(args = None, _real_data=real_data, _synthetic=real_data, _metrics=metrics)\n",
    "    crp = synthcity_results['mean'][1]\n",
    "    nsnd = 1-synthcity_results['mean'][2]\n",
    "    cvp = synthcity_results['mean'][3]\n",
    "    dvp = 1-synthcity_results['mean'][4]\n",
    "    auth = synthcity_results['mean'][10]\n",
    "    mlp = synthcity_results['mean'][11]\n",
    "    id_score = synthcity_results['mean'][12]\n",
    "    air = AIR.calculate_metric(args = None, _real_data=real_data, _synthetic=syn_data)\n",
    "    gcap = GCAP.calculate_metric(args = None, _real_data=real_labels, _synthetic=syn_labels)\n",
    "    zcap = CZCAP.calculate_metric(args = None, _real_data=real_labels, _synthetic=syn_labels)\n",
    "    mdcr = MDCR.calculate_metric(args=None, _real_data=real_labels, _synthetic=syn_labels)\n",
    "    hitR = Hitting_rate.calculate_metric(args=None, _real_data=real_labels, _synthetic=syn_labels)\n",
    "    mir = MIR.calculate_metric(args=None, _real_data=real_labels, _synthetic=syn_labels)\n",
    "    nnaa = NNAA.calculate_metric(args=None, _real_data=real_labels, _synthetic=syn_labels)\n",
    "    dcr = DCR.calculate_metric(args=None, _real_data=real_labels, _synthetic=syn_labels)\n",
    "    nndr = NNDR.calculate_metric(args=None, _real_data=real_labels, _synthetic=syn_labels)\n",
    "    hidd = Hidden_rate.calculate_metric(args=None, _real_data=real_labels, _synthetic=syn_labels)\n",
    "     \n",
    "    priv_results = np.around([air, gcap, zcap, \n",
    "                            mdcr, hitR, mir, \n",
    "                            nnaa, crp, nsnd, \n",
    "                            cvp, dvp, auth, \n",
    "                            mlp, id_score, \n",
    "                            dcr, nndr, hidd\n",
    "                            ], 2).tolist()\n",
    "    \n",
    "    metric_list = [\"Attribute Inference Risk\", \"GeneralizedCAP\", \"ZeroCAP\", \n",
    "                   \"Median Distance to Closest Record\", \"Hitting Rate\",\n",
    "                   \"Membership Inference Risk\", \"Nearest Neighbour Adversarial Accuracy\",\n",
    "                   \"Common Row Proportion\", \"Nearest Synthetic Neighbour Distance\",\n",
    "                   \"Close Value Probability\", \"Distant Value Probability\",\n",
    "                   \"Authenticity\", \"DetectionMLP\", \"Identifiability Score\"\n",
    "                   , \"Distance to Closest Record\", \"Nearest Neighbour Distance Ratio\", \"Hidden Rate\"\n",
    "                   ]\n",
    "    \n",
    "    results = pd.DataFrame({'Metric':metric_list, 'Result':priv_results})\n",
    "    \n",
    "    return results\n",
    "\n",
    "eps_list = [0.02, 0.05, 0.1, 0.2, 0.5, 1, 2.5, 5]\n",
    "\n",
    "for eps in eps_list:\n",
    "    syn_no = pd.read_csv(f\"demo_syn/syn_no_1_{eps}.csv\")\n",
    "    get_metric_results(real_data, syn_no).to_csv(f\"metric_results/syn_no_1_{eps}.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Metric Results for Tabsyn\n",
    "\n",
    "Here is the code used to get the metric results for the SDG mechanism [Tabsyn](https://doi.org/10.48550/arXiv.2310.09656), using their provided dataset, namely, the [Shoppers](https://doi.org/10.24432/C5F88Q) dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[KeOps] Warning : omp.h header is not in the path, disabling OpenMP. To fix this, you can set the environment\n",
      "                  variable OMP_PATH to the location of the header before importing keopscore or pykeops,\n",
      "                  e.g. using os.environ: import os; os.environ['OMP_PATH'] = '/path/to/omp/header'\n",
      "[KeOps] Warning : Cuda libraries were not detected on the system or could not be loaded ; using cpu only mode\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "import pandas as pd\n",
    "from sklearn.manifold import TSNE\n",
    "from get_metric_results import get_metric_results\n",
    "\n",
    "df = pd.read_csv(\"Data/real.csv\", index_col=False)\n",
    "syn_df = pd.read_csv(\"Data/tabsyn.csv\", index_col=False)\n",
    "\n",
    "all_data = pd.concat([df, syn_df], ignore_index=True)\n",
    "\n",
    "cat_cols = all_data.select_dtypes(include=['object', 'bool']).columns\n",
    "\n",
    "# Initialize a dictionary to hold encoded data\n",
    "encoded_data = {}\n",
    "for col in cat_cols:\n",
    "    if all_data[col].dtype == 'bool':\n",
    "        encoded_data[col] = all_data[col].astype(int)\n",
    "    else:\n",
    "        le = LabelEncoder()\n",
    "        encoded_data[col] = le.fit_transform(all_data[col].astype(str))\n",
    "\n",
    "num_cols = all_data.select_dtypes(exclude=['object', 'bool']).columns\n",
    "for col in num_cols:\n",
    "    encoded_data[col] = all_data[col]\n",
    "\n",
    "all_labels = pd.DataFrame(encoded_data)\n",
    "real_len = len(df)\n",
    "real_labels = all_labels[:real_len]\n",
    "syn_labels = all_labels[real_len:]\n",
    "\n",
    "metric_results = get_metric_results(df, syn_df, real_labels, syn_labels, sensitive_attributes=['Revenue'])\n",
    "print(\"Metric Results:\")\n",
    "print(metric_results)\n",
    "\n",
    "metric_results.to_csv(\"metric_results/tabsyn_metric_results.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Metric Results for PrivBayes\n",
    "\n",
    "Here is the code used to get the metric results for the SDG mechanism [PrivBayes](https://doi.org/10.1145/3134428), using the dataset used in TabSyn, namely, the [Shoppers](https://doi.org/10.24432/C5F88Q) dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Synthesize the dataset with PrivBayes\n",
    "from synthesis.synthesizers.privbayes import PrivBayes\n",
    "\n",
    "def synthesize_no_bin(real_data, eps):    \n",
    "    # instantiate and fit synthesizer\n",
    "    pb = PrivBayes(epsilon=eps, verbose=False)\n",
    "    pb.fit(real_data)\n",
    "\n",
    "    # Synthesize data\n",
    "    gen_data  = pb.sample()\n",
    "\n",
    "    # Save to csv file\n",
    "    result = pd.DataFrame(gen_data.values, columns=gen_data.columns, index=range(real_data.shape[0]))\n",
    "    \n",
    "    return result\n",
    "\n",
    "df = pd.read_csv('Data/real.csv')\n",
    "epsilon = [0.02, 0.05, 0.1, 0.2, 0.5, 1.0, 2.5, 5.0]\n",
    "for eps in epsilon:\n",
    "    synthesized_data = synthesize_no_bin(df, eps)\n",
    "    synthesized_data.to_csv(f'Data/privbayes(e={eps}).csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get metric results for PrivBayes\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import pandas as pd\n",
    "from get_metric_results import get_metric_results\n",
    "\n",
    "df = pd.read_csv(\"Data/real.csv\", index_col=False)\n",
    "epsilon = [0.02, 0.05, 0.1, 0.2, 0.5, 1.0, 2.5, 5.0]\n",
    "for eps in epsilon:\n",
    "    syn_df = pd.read_csv(f\"Data/privbayes(e={eps}).csv\", index_col=False)\n",
    "\n",
    "    all_data = pd.concat([df, syn_df], ignore_index=True)\n",
    "\n",
    "    cat_cols = all_data.select_dtypes(include=['object', 'bool']).columns\n",
    "\n",
    "    # Initialize a dictionary to hold encoded data\n",
    "    encoded_data = {}\n",
    "    for col in cat_cols:\n",
    "        if all_data[col].dtype == 'bool':\n",
    "            encoded_data[col] = all_data[col].astype(int)\n",
    "        else:\n",
    "            le = LabelEncoder()\n",
    "            encoded_data[col] = le.fit_transform(all_data[col].astype(str))\n",
    "\n",
    "    num_cols = all_data.select_dtypes(exclude=['object', 'bool']).columns\n",
    "    for col in num_cols:\n",
    "        encoded_data[col] = all_data[col]\n",
    "\n",
    "    all_labels = pd.DataFrame(encoded_data)\n",
    "    real_len = len(df)\n",
    "    real_labels = all_labels[:real_len]\n",
    "    syn_labels = all_labels[real_len:]\n",
    "\n",
    "    metric_results = get_metric_results(df, syn_df, real_labels, syn_labels, sensitive_attributes=['Revenue'])\n",
    "    print(\"Metric Results:\")\n",
    "    print(metric_results)\n",
    "\n",
    "    metric_results.to_csv(f\"metric_results/privbayes(e={eps})_metric_results.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
